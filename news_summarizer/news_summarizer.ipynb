{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMi3OXPxYuCFtqxfgHTHzfc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilamaiti/news_aggregator/blob/main/news_summarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install newspaper3k\n",
        "!pip install annotated-types==0.6.0\n",
        "!pip install anyio==4.3.0\n",
        "!pip install beautifulsoup4==4.12.3\n",
        "!pip install certifi==2024.2.2\n",
        "!pip install charset-normalizer==3.3.2\n",
        "!pip install colorama==0.4.6\n",
        "!pip install distro==1.9.0\n",
        "!pip install feedparser==6.0.11\n",
        "!pip install h11==0.14.0\n",
        "!pip install httpcore==1.0.5\n",
        "!pip install httpx==0.27.0\n",
        "!pip install idna==3.7\n",
        "!pip install openai==1.30.1\n",
        "!pip install pydantic==2.7.1\n",
        "!pip install pydantic_core==2.18.2\n",
        "!pip install python-dotenv==1.0.1\n",
        "!pip install requests==2.31.0\n",
        "!pip install sgmllib3k==1.0.0\n",
        "!pip install sniffio==1.3.1\n",
        "!pip install soupsieve==2.5\n",
        "!pip install tqdm==4.66.4\n",
        "!pip install typing_extensions==4.11.0\n",
        "!pip install urllib3==2.2.1\n",
        "!pip install langchain\n",
        "!pip install langchain-openai\n",
        "!pip install langchain[docarray]\n",
        "!pip install lxml\n",
        "!pip install xxhash"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoRuMGwszuLS",
        "outputId": "712baf70-595d-4ac4-b537-922dcdbf284b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting newspaper3k\n",
            "  Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (4.12.3)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (6.0.1)\n",
            "Collecting cssselect>=0.9.2 (from newspaper3k)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (4.9.4)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (3.8.1)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (2.31.0)\n",
            "Collecting feedparser>=5.2.1 (from newspaper3k)\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tldextract>=2.0.1 (from newspaper3k)\n",
            "  Downloading tldextract-5.1.2-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting feedfinder2>=0.0.4 (from newspaper3k)\n",
            "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jieba3k>=0.35.1 (from newspaper3k)\n",
            "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (2.8.2)\n",
            "Collecting tinysegmenter==0.3 (from newspaper3k)\n",
            "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\n",
            "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (4.66.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (2024.2.2)\n",
            "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k)\n",
            "  Downloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.14.0)\n",
            "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13538 sha256=8db7265068d517f65810c3a0ed6ef0fe9bd60467c80e216163b2df4635eb7406\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/d6/6c/384f58df48c00b9a31d638005143b5b3ac62c3d25fb1447f23\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3340 sha256=19ba59d1e9b26e4f543d534b97c1d2fe7987f3d0aecbba15e29b2264112b95d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/02/e7/a1ff1760e12bdbaab0ac824fae5c1bc933e41c4ccd6a8f8edb\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398382 sha256=da92744679cd0595e5f6667ade83fabd97c3631c1782a32da2c2cdf368a1fa7f\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/c4/0c/12a9a314ecac499456c4c3b2fcc2f635a3b45a39dfbd240299\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6049 sha256=b78b749f7c6ed3838f4a67e71981e93ec63f873010271ecd2bd85ad941cbcf20\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
            "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
            "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, feedparser, cssselect, requests-file, feedfinder2, tldextract, newspaper3k\n",
            "Successfully installed cssselect-1.2.0 feedfinder2-0.0.4 feedparser-6.0.11 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-2.1.0 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-5.1.2\n",
            "Collecting annotated-types==0.6.0\n",
            "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: annotated-types\n",
            "  Attempting uninstall: annotated-types\n",
            "    Found existing installation: annotated-types 0.7.0\n",
            "    Uninstalling annotated-types-0.7.0:\n",
            "      Successfully uninstalled annotated-types-0.7.0\n",
            "Successfully installed annotated-types-0.6.0\n",
            "Collecting anyio==4.3.0\n",
            "  Downloading anyio-4.3.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio==4.3.0) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio==4.3.0) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio==4.3.0) (1.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1 in /usr/local/lib/python3.10/dist-packages (from anyio==4.3.0) (4.11.0)\n",
            "Installing collected packages: anyio\n",
            "  Attempting uninstall: anyio\n",
            "    Found existing installation: anyio 3.7.1\n",
            "    Uninstalling anyio-3.7.1:\n",
            "      Successfully uninstalled anyio-3.7.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-server 1.24.0 requires anyio<4,>=3.1.0, but you have anyio 4.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed anyio-4.3.0\n",
            "Requirement already satisfied: beautifulsoup4==4.12.3 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4==4.12.3) (2.5)\n",
            "Requirement already satisfied: certifi==2024.2.2 in /usr/local/lib/python3.10/dist-packages (2024.2.2)\n",
            "Requirement already satisfied: charset-normalizer==3.3.2 in /usr/local/lib/python3.10/dist-packages (3.3.2)\n",
            "Collecting colorama==0.4.6\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n",
            "Collecting distro==1.9.0\n",
            "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: distro\n",
            "  Attempting uninstall: distro\n",
            "    Found existing installation: distro 1.7.0\n",
            "    Uninstalling distro-1.7.0:\n",
            "      Successfully uninstalled distro-1.7.0\n",
            "Successfully installed distro-1.9.0\n",
            "Requirement already satisfied: feedparser==6.0.11 in /usr/local/lib/python3.10/dist-packages (6.0.11)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.10/dist-packages (from feedparser==6.0.11) (1.0.0)\n",
            "Collecting h11==0.14.0\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11\n",
            "Successfully installed h11-0.14.0\n",
            "Collecting httpcore==1.0.5\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpcore==1.0.5) (2024.2.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.0.5) (0.14.0)\n",
            "Installing collected packages: httpcore\n",
            "Successfully installed httpcore-1.0.5\n",
            "Collecting httpx==0.27.0\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.0) (4.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.0) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.0) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.0) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.0) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx==0.27.0) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx==0.27.0) (1.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx==0.27.0) (4.11.0)\n",
            "Installing collected packages: httpx\n",
            "Successfully installed httpx-0.27.0\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.10/dist-packages (3.7)\n",
            "Collecting openai==1.30.1\n",
            "  Downloading openai-1.30.1-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.30.1) (4.3.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.30.1) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.30.1) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.30.1) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.30.1) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.30.1) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.30.1) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.30.1) (3.7)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.30.1) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.30.1) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.30.1) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.30.1) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.30.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.30.1) (2.18.2)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-1.30.1\n",
            "Requirement already satisfied: pydantic==2.7.1 in /usr/local/lib/python3.10/dist-packages (2.7.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.7.1) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.7.1) (4.11.0)\n",
            "Requirement already satisfied: pydantic_core==2.18.2 in /usr/local/lib/python3.10/dist-packages (2.18.2)\n",
            "Requirement already satisfied: typing-extensions!=4.7.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic_core==2.18.2) (4.11.0)\n",
            "Collecting python-dotenv==1.0.1\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (2024.2.2)\n",
            "Requirement already satisfied: sgmllib3k==1.0.0 in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: sniffio==1.3.1 in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Requirement already satisfied: soupsieve==2.5 in /usr/local/lib/python3.10/dist-packages (2.5)\n",
            "Requirement already satisfied: tqdm==4.66.4 in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "Requirement already satisfied: typing_extensions==4.11.0 in /usr/local/lib/python3.10/dist-packages (4.11.0)\n",
            "Collecting urllib3==2.2.1\n",
            "  Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: urllib3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "Successfully installed urllib3-2.2.1\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.2.1-py3-none-any.whl (973 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.5/973.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_core-0.2.1-py3-none-any.whl (308 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.5/308.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.0-py3-none-any.whl (23 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.63-py3-none-any.whl (122 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.8/122.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.0->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.3.0,>=0.2.0->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Installing collected packages: packaging, orjson, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-server 1.24.0 requires anyio<4,>=3.1.0, but you have anyio 4.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed jsonpatch-1.33 jsonpointer-2.4 langchain-0.2.1 langchain-core-0.2.1 langchain-text-splitters-0.2.0 langsmith-0.1.63 orjson-3.10.3 packaging-23.2\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.1.7-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.1.46 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.2.1)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.30.1)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai) (0.1.63)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai) (2.7.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai) (8.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.3.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.46->langchain-openai) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.46->langchain-openai) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain-openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain-openai) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.1)\n",
            "Installing collected packages: tiktoken, langchain-openai\n",
            "Successfully installed langchain-openai-0.1.7 tiktoken-0.7.0\n",
            "Requirement already satisfied: langchain[docarray] in /usr/local/lib/python3.10/dist-packages (0.2.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (0.2.1)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (0.2.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (0.1.63)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (8.3.0)\n",
            "Collecting docarray[hnswlib]<0.33.0,>=0.32.0 (from langchain[docarray])\n",
            "  Downloading docarray-0.32.1-py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (1.9.4)\n",
            "Requirement already satisfied: orjson>=3.8.2 in /usr/local/lib/python3.10/dist-packages (from docarray[hnswlib]<0.33.0,>=0.32.0->langchain[docarray]) (3.10.3)\n",
            "Requirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.10/dist-packages (from docarray[hnswlib]<0.33.0,>=0.32.0->langchain[docarray]) (13.7.1)\n",
            "Collecting types-requests>=2.28.11.6 (from docarray[hnswlib]<0.33.0,>=0.32.0->langchain[docarray])\n",
            "  Downloading types_requests-2.32.0.20240523-py3-none-any.whl (15 kB)\n",
            "Collecting typing-inspect>=0.8.0 (from docarray[hnswlib]<0.33.0,>=0.32.0->langchain[docarray])\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting hnswlib>=0.6.2 (from docarray[hnswlib]<0.33.0,>=0.32.0->langchain[docarray])\n",
            "  Downloading hnswlib-0.8.0.tar.gz (36 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from docarray[hnswlib]<0.33.0,>=0.32.0->langchain[docarray]) (3.20.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain[docarray]) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain[docarray]) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain[docarray]) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain[docarray]) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain[docarray]) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain[docarray]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain[docarray]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain[docarray]) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain[docarray]) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain[docarray]) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain[docarray]) (2.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.1.0->docarray[hnswlib]<0.33.0,>=0.32.0->langchain[docarray]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.1.0->docarray[hnswlib]<0.33.0,>=0.32.0->langchain[docarray]) (2.16.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->docarray[hnswlib]<0.33.0,>=0.32.0->langchain[docarray])\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray[hnswlib]<0.33.0,>=0.32.0->langchain[docarray]) (0.1.2)\n",
            "Building wheels for collected packages: hnswlib\n",
            "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hnswlib: filename=hnswlib-0.8.0-cp310-cp310-linux_x86_64.whl size=2319656 sha256=460aeddf2c2657e3c9bf6ce8b1c624ccacb96918ff2b872a949dc604675ab16b\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/a9/3e/3e5d59ee41664eb31a4e6de67d1846f86d16d93c45f277c4e7\n",
            "Successfully built hnswlib\n",
            "Installing collected packages: types-requests, mypy-extensions, hnswlib, typing-inspect, docarray\n",
            "Successfully installed docarray-0.32.1 hnswlib-0.8.0 mypy-extensions-1.0.0 types-requests-2.32.0.20240523 typing-inspect-0.9.0\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (4.9.4)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash\n",
            "Successfully installed xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-G9Advv2gGQ",
        "outputId": "3991418c-f697-4737-d79e-b285274deaf9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.30.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (4.3.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRogZNmJ2zYR",
        "outputId": "ba00ffce-ebf9-4b34-b651-2adf91ec43a0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Fvqh-NfzZML",
        "outputId": "6fb2b800-796c-4873-f607-476498b43e9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from textblob import TextBlob\n",
        "import openai\n",
        "import newspaper\n",
        "from newspaper import Article\n",
        "from newspaper import fulltext\n",
        "import feedparser\n",
        "import requests\n",
        "import os\n",
        "import concurrent.futures\n",
        "from configparser import ConfigParser\n",
        "import re\n",
        "import shelve\n",
        "import xxhash\n",
        "import threading\n",
        "from queue import Queue\n",
        "from datetime import datetime, timedelta\n",
        "import feedparser\n",
        "from dotenv import load_dotenv\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "import json\n",
        "from dotenv import load_dotenv\n",
        "import openai\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "os.environ['GDRIVE_CONFIG_DIR'] = \"/content/drive/MyDrive\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download required NLTK data\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4eH9VkTzcl1",
        "outputId": "b96c614a-c553-4eb1-eb10-c81f95f9de52"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf .env\n",
        "!touch .env\n",
        "!cat /content/drive/MyDrive/openai_api_key.txt >> .env"
      ],
      "metadata": {
        "id": "ksPw5VwOXwHN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(\".env\"):\n",
        "    print(\"Error: .env file not found. Please create a .env file and set the OPENAI_API_KEY environment variable.\")\n",
        "    exit(1)"
      ],
      "metadata": {
        "id": "nhrX3AJTYA3Z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv()\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "id": "2FuLl7n82apH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aws_url='https://aws.amazon.com/about-aws/whats-new/recent/feed/'\n",
        "azure_url='https://azurecomcdn.azureedge.net/en-us/updates/feed/'\n",
        "financial_feed_url='https://www.ft.com/news-feed'\n",
        "num_days=7\n",
        "model='gpt-3.5-turbo'\n",
        "temperature=0.5\n",
        "max_tokens=64\n",
        "top_p=1"
      ],
      "metadata": {
        "id": "qY7KJoGvYlTf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_rss_articles(urls):\n",
        "    \"\"\"Fetches articles from the given RSS feed URLs.\"\"\"\n",
        "    articles = []\n",
        "    count = 0\n",
        "    img_count = 0\n",
        "    for url in urls:\n",
        "        print(f\"Fetching articles from {url}...\")\n",
        "        feed = feedparser.parse(url)\n",
        "        if feed.bozo:\n",
        "            print(f\"Error fetching articles from {url}: {feed.bozo_exception}\")\n",
        "            continue\n",
        "\n",
        "        for entry in feed.entries:\n",
        "            article = {\n",
        "                \"id\": count,\n",
        "                \"title\": entry.title,\n",
        "                \"link\": entry.link,\n",
        "                \"published\": entry.get(\"published\", \"\"),\n",
        "                \"updated\": entry.get(\"updated\", \"\"),\n",
        "                \"content\": \"\",\n",
        "                \"image\": \"\",\n",
        "            }\n",
        "\n",
        "            # If 'content' is an array, merge all elements into a single string\n",
        "            if hasattr(entry, \"content\") and isinstance(entry.content, list):\n",
        "                content_merged = \"\".join([item.value for item in entry.content])\n",
        "                article[\"content\"] = content_merged\n",
        "            elif hasattr(entry, \"description\"):\n",
        "                article[\"content\"] = entry.description\n",
        "\n",
        "\n",
        "            # Extracting the first image from the content\n",
        "            article[\"image\"] = find_the_first_image(article[\"content\"])\n",
        "            # Clean the HTML content\n",
        "            article[\"content\"] = clean_html_content(article[\"content\"])\n",
        "            if article[\"image\"]:\n",
        "                # print(f\"Found image: {article['image']}\")\n",
        "                img_count += 1\n",
        "\n",
        "            articles.append(article)\n",
        "            count += 1\n",
        "    print(f\"Fetched {count} articles, {img_count} with images.\")\n",
        "    return articles\n",
        "\n",
        "def summarize_text(text, model = model, temperature = temperature, max_tokens = max_tokens, top_p = top_p, n_sentence = 1):\n",
        "    \"\"\"\n",
        "    This function uses the OpenAI Chat completion api to summarize provided text.\n",
        "\n",
        "    :param text: the text which will be summarized\n",
        "    :return: summarized text\n",
        "    \"\"\"\n",
        "    if n_sentence == 1:\n",
        "        response = openai.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"Summarize content you are provided with for a company executive with key points, highlights.\"\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": f\"Summarize the following text in {n_sentence} sentence:\\n\\n{text}\"\n",
        "                }\n",
        "                ],\n",
        "            temperature=temperature,\n",
        "            max_tokens=max_tokens,\n",
        "            top_p=top_p\n",
        "        )\n",
        "    else:\n",
        "            response = openai.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"Summarize content you are provided with for a company executive with key points, highlights.\"\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": f\"Summarize the following text in few sentences:\\n\\n{text}\"\n",
        "                }\n",
        "            ],\n",
        "            temperature=temperature,\n",
        "            max_tokens=max_tokens,\n",
        "            top_p=top_p\n",
        "        )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def get_keywords_from_text(text, model = model, temperature = temperature, max_tokens = max_tokens, top_p = top_p):\n",
        "    \"\"\"\n",
        "    This function uses the OpenAI Chat completion api to summarize provided text.\n",
        "\n",
        "    :param text: the text which will be summarized\n",
        "    :return: summarized text\n",
        "    \"\"\"\n",
        "    response = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"Get the key words from the content you are provided with for a company executive.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Extract top 5 key words from the following text:\\n\\n{text}\"\n",
        "            }\n",
        "        ],\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "        top_p=top_p\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def process_entry(entry, one_week_ago):\n",
        "    \"\"\"\n",
        "    Process single feed.\n",
        "    :param entry: to be processed\n",
        "    :param one_week_ago: published date to be filtered\n",
        "    :return: dict\n",
        "    \"\"\"\n",
        "    published_date = datetime.strptime(entry.published, '%a, %d %b %Y %H:%M:%S %Z')\n",
        "\n",
        "    if published_date >= one_week_ago:\n",
        "        rss_summary = summarize_text(entry.summary)\n",
        "        # Initialize an Article object with the specified URL\n",
        "        article = Article(entry.link)\n",
        "        article_summary = summarize_text(article.summary, n_sentence = 5)\n",
        "        return {\n",
        "            'title': entry.title,\n",
        "            'link': entry.link,\n",
        "            'published': published_date.strftime('%Y-%m-%d'),\n",
        "            'rss_summary': rss_summary,\n",
        "            'article_summary': article_summary\n",
        "        }\n",
        "    return None\n",
        "\n",
        "\n",
        "def fetch_parsed_feed(filtered_entries, aws_url = financial_feed_url, azure_url = azure_url, num_days = num_days):\n",
        "    \"\"\"\n",
        "    Fetching the feed to be parsed.\n",
        "\n",
        "    :return: the feed\n",
        "    \"\"\"\n",
        "    rss_url = aws_url\n",
        "\n",
        "    now = datetime.now()\n",
        "    one_week_ago = now - timedelta(days=num_days)\n",
        "\n",
        "    feed = feedparser.parse(rss_url)\n",
        "\n",
        "    if feed.bozo:\n",
        "        print(\"Failed to parse the RSS feed.\")\n",
        "        exit(1)\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        futures = [executor.submit(process_entry, entry, one_week_ago) for entry in feed.entries if 'summary' in list(dict(entry).keys())]\n",
        "\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            result = future.result()\n",
        "            if result:\n",
        "                filtered_entries.append(result)\n",
        "\n",
        "    return filtered_entries\n",
        "\n",
        "def create_report(entries):\n",
        "    \"\"\"\n",
        "    Creates the html report\n",
        "\n",
        "    :param entries: news which were parsed\n",
        "    :return: nothing, creates the actual html report file\n",
        "    \"\"\"\n",
        "\n",
        "    html_content = \"\"\"\n",
        "<html>\n",
        "<head>\n",
        "    <title>News</title>\n",
        "    <style>\n",
        "        body {\n",
        "            font-family: Arial, sans-serif;\n",
        "        }\n",
        "        .panel {\n",
        "            background-color: #ffffff;\n",
        "            border: 1px solid #ccc;\n",
        "            border-radius: 5px;\n",
        "            margin: 10px 0;\n",
        "            padding: 10px;\n",
        "            cursor: pointer;\n",
        "        }\n",
        "        .panel-title {\n",
        "            font-size: 18px;\n",
        "            font-weight: bold;\n",
        "        }\n",
        "        .panel-content {\n",
        "            display: none;\n",
        "            margin-top: 10px;\n",
        "        }\n",
        "    </style>\n",
        "    <script>\n",
        "        function togglePanelContent(panel) {\n",
        "            var content = panel.querySelector('.panel-content');\n",
        "            if (content.style.display === 'none' || content.style.display === '') {\n",
        "                content.style.display = 'block';\n",
        "            } else {\n",
        "                content.style.display = 'none';\n",
        "            }\n",
        "        }\n",
        "    </script>\n",
        "</head>\n",
        "<body>\n",
        "    <h1>Financial News</h1>\n",
        "\"\"\"\n",
        "    for entry in entries:\n",
        "        html_content += f\"\"\"\n",
        "        <div class=\"panel\" onclick=\"togglePanelContent(this)\">\n",
        "            <div class=\"panel-title\">{entry['title']}</div>\n",
        "            <div class=\"panel-content\">\n",
        "                <p><strong>Link:</strong> <a href=\"{entry['link']}\">{entry['link']}</a></p>\n",
        "                <p><strong>AI Highlights:</strong> {entry['rss_summary']}</p>\n",
        "                <p><strong>AI Summary:</strong> {entry['article_summary']}</p>\n",
        "            </div>\n",
        "        </div>\n",
        "    \"\"\"\n",
        "    html_content += \"\"\"\n",
        "    </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "\n",
        "    with open(\"newsBoard.html\", \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(html_content)\n",
        "    print(\"The news entries have been saved.\")"
      ],
      "metadata": {
        "id": "cw1J4Hc7Zaoi"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_entries = []\n",
        "fetch_parsed_feed(filtered_entries)\n",
        "create_report(filtered_entries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZNKG2xNa1Cm",
        "outputId": "44b44a8a-d584-4b40-ab36-3c5f8f1873d9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The news entries have been saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_paper = newspaper.build('http://cnn.com')\n",
        "for article in cnn_paper.articles:\n",
        "    print(article.url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLJ0jb3t1DuJ",
        "outputId": "c4b76f86-da78-47d6-bd45-7bd138123c4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRITICAL:newspaper.network:[REQUEST FAILED] 404 Client Error: Not Found for url: http://www.cnn.com/feeds\n",
            "CRITICAL:newspaper.network:[REQUEST FAILED] 404 Client Error: Not Found for url: http://www.cnn.com/feed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://cnn.com/2024/05/21/politics/takeaways-from-donald-trumps-defense-in-the-hush-money-trial/index.html\n",
            "http://cnn.com/2024/05/21/middleeast/european-hospital-gaza-medics-freed-intl-latam/index.html\n",
            "http://cnn.com/2024/05/17/opinions/open-ai-chatgpt-4o-yang/index.html\n",
            "http://cnn.com/2024/05/21/politics/rudy-giuliani-arizona-election-subversion/index.html\n",
            "http://cnn.com/2024/05/21/politics/us-assesses-russia-launched-counter-space-weapon/index.html\n",
            "http://cnn.com/2024/05/21/us/grizzly-bear-attack-wyoming/index.html\n",
            "http://cnn.com/2024/05/21/us/deaths-falls-hiking-climbing-parks/index.html\n",
            "http://cnn.com/2024/05/21/cars/vinfast-regulators-investigating-fatal-crash-ev/index.html\n",
            "http://cnn.com/2024/05/21/uk/us-embassy-london-congestion-fees-scli-intl/index.html\n",
            "http://cnn.com/2024/05/06/climate/video/refreeze-arctic-sea-ice-technology-ldn-digvid\n",
            "http://cnn.com/2024/05/21/world/video/raisi-funeral-procession-tabriz-tehran-iran-ldn-digvid\n",
            "http://cnn.com/2024/05/21/style/huia-feather-sold-new-zealand-intl-scli/index.html\n",
            "http://cnn.com/2024/05/21/investing/jamie-dimon-jpmorgan-succession-plan/index.html\n",
            "http://cnn.com/cnn-underscored/electronics/apple-airpods-max-vs-beats-solo-4\n",
            "http://cnn.com/2024/05/21/entertainment/misa-hylton-statement-diddy-cassie/index.html\n",
            "http://cnn.com/travel/fujikawaguchiko-japan-photo-blocking-barrier-intl-hnk/index.html\n",
            "http://cnn.com/2024/05/20/travel/lauterbrunnen-visitor-entry-fee-switzerland-intl-scli/index.html\n",
            "http://cnn.com/2024/05/16/style/cannes-film-festival-fashion/index.html\n",
            "http://cnn.com/2024/05/20/style/kehinde-wiley-joseph-awuah-darko-sexual-assault-accusations/index.html\n",
            "http://cnn.com/2024/05/18/style/sports-illustrated-swimsuit-issue-anniversary-covers/index.html\n",
            "http://cnn.com/2024/05/21/world/stonehenge-moon-lunar-standstill-scn/index.html\n",
            "http://cnn.com/2024/05/21/health/teen-social-media-mental-health-wellness/index.html\n",
            "https://bleacherreport.com/articles/10121917-takeru-kobayashi-retires-from-competitive-eating-won-6-hot-dog-eating-contests?utm_source=cnn.com&utm_medium=referral&utm_campaign=editorial\n",
            "https://bleacherreport.com/articles/10121851-ricky-stenhouse-jr-kyle-busch-get-celebrity-boxing-offer-after-nascar-fight-video?utm_source=cnn.com&utm_medium=referral&utm_campaign=editorial\n",
            "https://edition.cnn.com/2024/05/21/politics/takeaways-from-donald-trumps-defense-in-the-hush-money-trial/index.html\n",
            "https://edition.cnn.com/2024/05/21/politics/rudy-giuliani-arizona-election-subversion/index.html\n",
            "https://edition.cnn.com/2024/05/21/uk/us-embassy-london-congestion-fees-scli-intl/index.html\n",
            "https://edition.cnn.com/2024/05/21/world/stonehenge-moon-lunar-standstill-scn/index.html\n",
            "https://edition.cnn.com/2024/05/21/style/huia-feather-sold-new-zealand-intl-scli/index.html\n",
            "https://edition.cnn.com/2024/05/21/health/teen-social-media-mental-health-wellness/index.html\n",
            "https://cnnespanol.cnn.com/2024/05/21/opinion-ghitis-presidente-iran-raisi-muerto-lucha-poder-trax/\n",
            "https://cnnespanol.cnn.com/2024/05/20/presidente-iran-ebrahim-raisi-murio-cargo-que-sigue-trax/\n",
            "https://cnnespanol.cnn.com/2024/05/21/empresarios-venezolanos-incentivos-ley-pensiones-gobierno-maduro-orix/\n",
            "https://cnnespanol.cnn.com/2024/05/21/implacable-sistema-tormentoso-medio-oeste-vientos-tornados-trax/\n",
            "https://cnnespanol.cnn.com/2024/05/21/rusia-inicia-primera-fase-ejercicios-armas-nucleares-tacticas-trax/\n",
            "https://cnnespanol.cnn.com/2024/05/21/braceros-anciano-regreso-texas-historia-trax/\n",
            "https://cnnespanol.cnn.com/2024/05/21/redes-sociales-informe-jovenes-trax/\n",
            "https://cnnespanol.cnn.com/video/muerto-turbulencia-vuelo-singapore-airlines-trax/\n",
            "https://cnnespanol.cnn.com/2024/05/21/honduras-guatemala-calidad-aire-region-orix/\n",
            "https://cnnespanol.cnn.com/2024/05/21/elecciones-mexico-2024-noticias-ultima-hora-sheinbaum-galvez-maynez-orix-4/\n",
            "https://cnnespanol.cnn.com/video/disfraces-perros-pet-gala-ush-cafe-tv/\n",
            "https://cnnespanol.cnn.com/video/ordenes-arresto-cpi-netanyahu-reaccion-trax/\n",
            "https://cnnespanol.cnn.com/video/ceremonias-funebres-muerte-presidente-iran-ebrahim-raisi-cafe-tv/\n",
            "https://cnnespanol.cnn.com/video/tapan-monte-fuji-turistas-japon-cafe-tv/\n",
            "https://cnnespanol.cnn.com/video/milei-declaraciones-pedro-sanchez-embajada-espana-orix/\n",
            "https://cnnespanol.cnn.com/2024/05/21/tribunal-de-londres-impide-al-principe-harry-incluir-acusaciones-contra-murdoch-en-demada-en-curso-trax/\n",
            "https://cnnespanol.cnn.com/2024/05/21/microsoft-pc-relevantes-computadoras-ia-inteligencia-artificial-trax/\n",
            "https://cnnespanol.cnn.com/video/messi-mls-mejores-salarios-deportes-orix/\n",
            "https://arabic.cnn.com/middle-east/article/2024/05/21/blinken-israel-will-have-to-decide-normalization-saudi-arabia\n",
            "https://arabic.cnn.com/middle-east/video/2024/05/21/v156425-iran-raisi-mourning-wedeman-liveshot-052108aseg1-cnni-world-fast\n",
            "https://us.cnn.com/2024/05/21/politics/takeaways-from-donald-trumps-defense-in-the-hush-money-trial/index.html\n",
            "https://us.cnn.com/2024/05/21/middleeast/european-hospital-gaza-medics-freed-intl-latam/index.html\n",
            "https://us.cnn.com/2024/05/17/opinions/open-ai-chatgpt-4o-yang/index.html\n",
            "https://us.cnn.com/2024/05/21/politics/rudy-giuliani-arizona-election-subversion/index.html\n",
            "https://us.cnn.com/2024/05/21/politics/us-assesses-russia-launched-counter-space-weapon/index.html\n",
            "https://us.cnn.com/2024/05/21/us/grizzly-bear-attack-wyoming/index.html\n",
            "https://us.cnn.com/2024/05/21/us/deaths-falls-hiking-climbing-parks/index.html\n",
            "https://us.cnn.com/2024/05/21/cars/vinfast-regulators-investigating-fatal-crash-ev/index.html\n",
            "https://us.cnn.com/2024/05/21/uk/us-embassy-london-congestion-fees-scli-intl/index.html\n",
            "https://us.cnn.com/2024/05/06/climate/video/refreeze-arctic-sea-ice-technology-ldn-digvid\n",
            "https://us.cnn.com/2024/05/21/world/video/raisi-funeral-procession-tabriz-tehran-iran-ldn-digvid\n",
            "https://us.cnn.com/2024/05/21/style/huia-feather-sold-new-zealand-intl-scli/index.html\n",
            "https://us.cnn.com/2024/05/21/investing/jamie-dimon-jpmorgan-succession-plan/index.html\n",
            "https://us.cnn.com/cnn-underscored/electronics/apple-airpods-max-vs-beats-solo-4\n",
            "https://us.cnn.com/2024/05/21/entertainment/misa-hylton-statement-diddy-cassie/index.html\n",
            "https://us.cnn.com/travel/fujikawaguchiko-japan-photo-blocking-barrier-intl-hnk/index.html\n",
            "https://us.cnn.com/2024/05/20/travel/lauterbrunnen-visitor-entry-fee-switzerland-intl-scli/index.html\n",
            "https://us.cnn.com/2024/05/16/style/cannes-film-festival-fashion/index.html\n",
            "https://us.cnn.com/2024/05/20/style/kehinde-wiley-joseph-awuah-darko-sexual-assault-accusations/index.html\n",
            "https://us.cnn.com/2024/05/18/style/sports-illustrated-swimsuit-issue-anniversary-covers/index.html\n",
            "https://us.cnn.com/2024/05/21/world/stonehenge-moon-lunar-standstill-scn/index.html\n",
            "https://us.cnn.com/2024/05/21/health/teen-social-media-mental-health-wellness/index.html\n",
            "https://money.cnn.com/2024/05/21/cars/vinfast-regulators-investigating-fatal-crash-ev/index.html\n",
            "https://money.cnn.com/2024/05/21/investing/jamie-dimon-jpmorgan-succession-plan/index.html\n",
            "https://money.cnn.com/2024/05/17/business/us-blocks-imports-china-uyghur-forced-labor-ink-intl/index.html\n",
            "https://money.cnn.com/2024/05/15/business/warren-buffett-berkshire-hathaway-chubb-stake/index.html\n",
            "https://money.cnn.com/2024/05/16/investing/mit-crypto-hack/index.html\n",
            "https://money.cnn.com/2024/05/16/business/jamie-dimon-ray-dalio-us-government-debt/index.html\n",
            "https://www.cnn.com/2024/05/21/politics/takeaways-from-donald-trumps-defense-in-the-hush-money-trial/index.html\n",
            "https://www.cnn.com/2024/05/21/middleeast/european-hospital-gaza-medics-freed-intl-latam/index.html\n",
            "https://www.cnn.com/2024/05/17/opinions/open-ai-chatgpt-4o-yang/index.html\n",
            "https://www.cnn.com/2024/05/21/politics/rudy-giuliani-arizona-election-subversion/index.html\n",
            "https://www.cnn.com/2024/05/21/politics/us-assesses-russia-launched-counter-space-weapon/index.html\n",
            "https://www.cnn.com/2024/05/21/us/grizzly-bear-attack-wyoming/index.html\n",
            "https://www.cnn.com/2024/05/21/us/deaths-falls-hiking-climbing-parks/index.html\n",
            "https://www.cnn.com/2024/05/21/cars/vinfast-regulators-investigating-fatal-crash-ev/index.html\n",
            "https://www.cnn.com/2024/05/21/uk/us-embassy-london-congestion-fees-scli-intl/index.html\n",
            "https://www.cnn.com/2024/05/06/climate/video/refreeze-arctic-sea-ice-technology-ldn-digvid\n",
            "https://www.cnn.com/2024/05/21/world/video/raisi-funeral-procession-tabriz-tehran-iran-ldn-digvid\n",
            "https://www.cnn.com/2024/05/21/style/huia-feather-sold-new-zealand-intl-scli/index.html\n",
            "https://www.cnn.com/2024/05/21/investing/jamie-dimon-jpmorgan-succession-plan/index.html\n",
            "https://www.cnn.com/cnn-underscored/electronics/apple-airpods-max-vs-beats-solo-4\n",
            "https://www.cnn.com/2024/05/21/entertainment/misa-hylton-statement-diddy-cassie/index.html\n",
            "https://www.cnn.com/travel/fujikawaguchiko-japan-photo-blocking-barrier-intl-hnk/index.html\n",
            "https://www.cnn.com/2024/05/20/travel/lauterbrunnen-visitor-entry-fee-switzerland-intl-scli/index.html\n",
            "https://www.cnn.com/2024/05/16/style/cannes-film-festival-fashion/index.html\n",
            "https://www.cnn.com/2024/05/20/style/kehinde-wiley-joseph-awuah-darko-sexual-assault-accusations/index.html\n",
            "https://www.cnn.com/2024/05/18/style/sports-illustrated-swimsuit-issue-anniversary-covers/index.html\n",
            "https://www.cnn.com/2024/05/21/world/stonehenge-moon-lunar-standstill-scn/index.html\n",
            "https://www.cnn.com/2024/05/21/health/teen-social-media-mental-health-wellness/index.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for category in cnn_paper.category_urls():\n",
        "    print(category)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65Z4Dehj1Ojo",
        "outputId": "8170da82-d484-497b-f4c8-5c5dd1b7da16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://cnn.com\n",
            "https://edition.cnn.com\n",
            "https://cnnespanol.cnn.com\n",
            "http://cnn.com/follow\n",
            "https://arabic.cnn.com\n",
            "https://us.cnn.com\n",
            "https://money.cnn.com\n",
            "https://www.cnn.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_article = cnn_paper.articles[0]\n",
        "cnn_article.download()\n",
        "cnn_article.parse()\n",
        "cnn_article.nlp()"
      ],
      "metadata": {
        "id": "LRzBswT3zcol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.cnn.com/2024/05/21/americas/us-lawmakers-turks-caicos-detained-americans/index.html\"\n",
        "# Initialize an Article object with the specified URL\n",
        "article = Article(url)\n",
        "\n",
        "# Download and parse the article's HTML\n",
        "article.download()\n",
        "article.parse()\n",
        "\n",
        "# Use natural language processing to extract useful information from the article\n",
        "article.nlp()"
      ],
      "metadata": {
        "id": "Q5UiH14yzcrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the article's title, author(s), publication date and summary\n",
        "print(f'Title: {article.title}')\n",
        "print('\\n')\n",
        "print(f'Authors: {article.authors}')\n",
        "print('\\n')\n",
        "print(f'Publication Date: {article.publish_date}')\n",
        "print('\\n')\n",
        "print(f'Summary: {article.summary}')\n",
        "\n",
        "# Analyze the sentiment of the article using TextBlob\n",
        "analysis = TextBlob(article.text)\n",
        "print('\\n')\n",
        "\n",
        "# Print the polarity (i.e. sentiment score) of the article\n",
        "print(f\"Polarity : {analysis.polarity}\")\n",
        "\n",
        "# Print whether the sentiment of the article is positive, negative, or neutral\n",
        "print(f'Sentiment: {\"Positive\" if analysis.polarity > 0 else \"Negative\" if analysis.polarity < 0 else \"Neutral\"}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXAqe-e3zcuM",
        "outputId": "a821adf0-0a99-49e2-8ea8-d8cf2625266f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Bipartisan group of lawmakers travel to Turks and Caicos to push for release of detained Americans\n",
            "\n",
            "\n",
            "Authors: ['Lauren Mascarenhas']\n",
            "\n",
            "\n",
            "Publication Date: 2024-05-21 00:00:00\n",
            "\n",
            "\n",
            "Summary: CNN —A bipartisan group of US lawmakers traveled to Turks and Caicos to press for the release of five Americans detained on ammunition possession charges – but encountered resistance from officials on the island, the group announced Monday.\n",
            "The lawmakers met with Turks and Caicos officials, including the governor, attorney general, minister of tourism and police leaders, the statement from Mullin’s office said.\n",
            "“Unfortunately, despite our willingness to work with Turks and Caicos officials to get our constituents home, we were not able to find a path forward today,” Mullin said in the statement.\n",
            "Bringing firearms or ammunition, including stray bullets, into Turks and Caicos without prior permission from police is “strictly forbidden,” according to a statement from its government.\n",
            "Judges can lower the minimum sentence and adjust fines when there are “exceptional circumstances,” the Turks and Caicos attorney general said in a news release earlier this month.\n",
            "\n",
            "\n",
            "Polarity : 0.047619047619047616\n",
            "Sentiment: Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_O-KUacmzc0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uCn9Ohh3zc3M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}