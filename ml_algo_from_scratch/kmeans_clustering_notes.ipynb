{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTkCvZvtMLFOQIDdtTqagh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilamaiti/srilamaiti.github.io/blob/main/ml_algo_from_scratch/kmeans_clustering_notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Means Clustering - Explained Simply\n",
        "\n",
        "K-Means is an unsupervised learning algorithm used for clustering data into K groups based on similarity.\n",
        "\n",
        "üîπ How K-Means Works (Simple Steps)\n",
        "\n",
        "1Ô∏è‚É£ Choose K\n",
        "\n",
        "Decide the number of clusters (K).\n",
        "\n",
        "2Ô∏è‚É£ Randomly Initialize K Centroids\n",
        "\n",
        "Pick K random points as the initial centers of clusters.\n",
        "\n",
        "3Ô∏è‚É£ Assign Data Points to Nearest Centroid\n",
        "\n",
        "Each data point is assigned to the closest centroid (using Euclidean distance).\n",
        "\n",
        "4Ô∏è‚É£ Recalculate Centroids\n",
        "\n",
        "Compute the mean of all points in each cluster to update the centroid.\n",
        "\n",
        "5Ô∏è‚É£ Repeat Steps 3 & 4 Until Convergence\n",
        "\n",
        "The process repeats until centroids no longer change or a maximum number of iterations is reached.\n",
        "\n",
        "üîπ Assumptions of K-Means\n",
        "\n",
        "1Ô∏è‚É£ Clusters are Spherical\n",
        "\n",
        "Each cluster is assumed to have a circular shape in space.\n",
        "\n",
        "2Ô∏è‚É£ Clusters Have Similar Sizes\n",
        "\n",
        "Works best when clusters have equal variance and similar density.\n",
        "\n",
        "3Ô∏è‚É£ Data is Continuous\n",
        "\n",
        "K-Means works best with numerical data, not categorical.\n",
        "\n",
        "4Ô∏è‚É£ Clusters are Well Separated\n",
        "\n",
        "If clusters overlap, K-Means may not work well.\n",
        "\n",
        "‚úÖ Advantages of K-Means\n",
        "\n",
        "‚úî Fast & Efficient\n",
        "\n",
        "Works well on large datasets due to its simplicity.\n",
        "\n",
        "‚úî Easy to Implement\n",
        "\n",
        "Only requires specifying K and runs iteratively.\n",
        "\n",
        "‚úî Works in High Dimensions\n",
        "\n",
        "Can handle multiple features well.\n",
        "\n",
        "‚úî Interpretable\n",
        "\n",
        "Simple clusters make it easy to understand.\n",
        "\n",
        "‚ùå Disadvantages of K-Means\n",
        "\n",
        "‚úñ Need to Choose K\n",
        "\n",
        "Choosing the right number of clusters (K) can be tricky.\n",
        "\n",
        "‚úñ Sensitive to Outliers\n",
        "\n",
        "A single outlier can distort cluster assignments.\n",
        "\n",
        "‚úñ Assumes Clusters Are Circular\n",
        "\n",
        "Doesn‚Äôt work well if clusters have irregular shapes.\n",
        "\n",
        "‚úñ Random Initialization Can Affect Results\n",
        "\n",
        "Different runs can give different cluster assignments.\n",
        "\n",
        "üìå When to Use K-Means?\n",
        "‚úÖ When you have unlabeled data\n",
        "\n",
        "Best for grouping similar items when no labels exist.\n",
        "\n",
        "‚úÖ When clusters are clearly separated\n",
        "\n",
        "Works well when data naturally falls into distinct groups.\n",
        "\n",
        "‚úÖ For large datasets\n",
        "\n",
        "Since it‚Äôs efficient, it‚Äôs great for big data clustering.\n",
        "\n",
        "‚úÖ When you need quick, simple clustering\n",
        "\n",
        "Ideal for exploratory analysis and pattern detection.\n",
        "\n",
        "üöÄ Key Takeaways\n",
        "\n",
        "Use K-Means when clusters are clearly defined and spherical.\n",
        "Avoid K-Means when data has overlapping clusters or many outliers.\n",
        "Choosing K wisely is critical ‚Äì use the Elbow Method or Silhouette Score."
      ],
      "metadata": {
        "id": "hR27hHGwyAAu"
      }
    }
  ]
}